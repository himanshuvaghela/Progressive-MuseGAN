{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the metric curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains functions for plotting the metric curves in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import errno\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with the bold roman font bug, see\n",
    "#   https://github.com/matplotlib/matplotlib/issues/5574\n",
    "matplotlib.font_manager._rebuild()\n",
    "matplotlib.rcParams['font.family'] = 'serif'\n",
    "matplotlib.rcParams['font.size'] = 16.0\n",
    "plt.rcParams['savefig.dpi'] = 120\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sure_path_exists(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exception:\n",
    "        if exception.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "def movingaverage (values, window):\n",
    "    weights = np.repeat(1.0, window)/window\n",
    "    sma = np.convolve(values, weights, 'valid')\n",
    "    return sma\n",
    "\n",
    "def color_variant(hex_color, brightness_offset=1):\n",
    "    \"\"\"Takes a hex color code and produces a lighter or darker variant.\"\"\"\n",
    "    if len(hex_color) != 7:\n",
    "        raise ValueError(\"Unrecognizable color code. Should be like #5F4B8B.\")\n",
    "    rgb_hex = [hex_color[x:x+2] for x in [1, 3, 5]]\n",
    "    rgb_int = [int(hex_value, 16) + brightness_offset for hex_value in rgb_hex]\n",
    "    rgb_int = [min([255, max([0, i])]) for i in rgb_int] \n",
    "    return \"#\" + \"\".join(['{:0>2}'.format(hex(i)[2:]) for i in rgb_int])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traing_data_eval_path = './data/training_data/lastfm_alternative_8b_phrase.npy'\n",
    "data_dir = './data/eval_training_progress/'\n",
    "result_dir = './figs/'\n",
    "extension = 'png' # 'pdf', 'ps', 'eps', 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sure_path_exists(result_dir)\n",
    "make_sure_path_exists(os.path.join(result_dir, 'two-stage'))\n",
    "make_sure_path_exists(os.path.join(result_dir, 'end2end'))\n",
    "make_sure_path_exists(os.path.join(result_dir, 'ablated'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_names = (\n",
    "    'Drums', 'Piano', 'Guitar', 'Bass', 'Ensemble', 'Reed', 'Synth Lead',\n",
    "    'Synth Pad'\n",
    ")\n",
    "metric_names = (\n",
    "    'empty bar rate', '# of pitch used', 'qualified note rate', 'polyphonicity',\n",
    "    'note in scale', 'drum in pattern rate', '# of chroma used'\n",
    ")\n",
    "metric_file_names = (\n",
    "    'empty_bar_rate', 'num_pitch_used', 'qualified_note_rate', 'polyphonicity',\n",
    "    'note_in_scale', 'drum_in_pattern', 'num_chroma_used'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load merged evaluation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics(filename, start_step=0):\n",
    "    \"\"\"Load a merged metric file and return it as a dictionary.\"\"\"\n",
    "    results = {}\n",
    "    with np.load(os.path.join(data_dir, filename)) as loaded:\n",
    "        results['steps'] = loaded['steps'] + start_step\n",
    "        results['score_matrix_means'] = loaded['score_matrix_means']\n",
    "        results['score_pair_matrix_means'] = loaded['score_pair_matrix_means']\n",
    "    return results\n",
    "\n",
    "def update_metrics(filename, metric_dict, start_step=0):\n",
    "    \"\"\"Update a metric array dictionary with a merged metric file.\"\"\"\n",
    "    with np.load(os.path.join(data_dir, filename)) as loaded:\n",
    "        mask = (metric_dict['steps'] < loaded['steps'].min() + start_step)\n",
    "        metric_dict['steps'] = np.concatenate(\n",
    "            (metric_dict['steps'][mask], loaded['steps'] + start_step)\n",
    "        )\n",
    "        metric_dict['score_matrix_means'] = np.concatenate(\n",
    "            (metric_dict['score_matrix_means'][mask],\n",
    "             loaded['score_matrix_means'])\n",
    "        )\n",
    "        metric_dict['score_pair_matrix_means'] = np.concatenate(\n",
    "            (metric_dict['score_pair_matrix_means'][mask],\n",
    "             loaded['score_pair_matrix_means'])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load(traing_data_eval_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_proposed = load_metrics(\"lastfm_alternative_pretrain_g_proposed_\"\n",
    "                                   \"d_proposed.npz\")\n",
    "pretrained_ablated = load_metrics(\"lastfm_alternative_pretrain_g_proposed_\"\n",
    "                                  \"d_ablated.npz\")\n",
    "pretrained_baseline = load_metrics(\"lastfm_alternative_pretrain_g_proposed_\"\n",
    "                                   \"d_baseline.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-stage models (proposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_step = 55470 # steps when second-stage training start\n",
    "proposed_round = load_metrics(\"lastfm_alternative_train_g_proposed_d_\"\n",
    "                              \"proposed_r_proposed_round.npz\",\n",
    "                              second_stage_step)\n",
    "proposed_bernoulli = load_metrics(\"lastfm_alternative_train_g_proposed_d_\"\n",
    "                                  \"proposed_r_proposed_bernoulli.npz\",\n",
    "                                  second_stage_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-stage models (joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_round = load_metrics(\"lastfm_alternative_train_joint_g_proposed_d_\"\n",
    "                           \"proposed_r_proposed_round.npz\", second_stage_step)\n",
    "joint_bernoulli = load_metrics(\"lastfm_alternative_train_joint_g_proposed_d_\"\n",
    "                               \"proposed_r_proposed_bernoulli.npz\",\n",
    "                               second_stage_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-end models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end2end_round = load_metrics(\"lastfm_alternative_end2end_g_proposed_small_d_\"\n",
    "                             \"proposed_r_proposed_round.npz\")\n",
    "end2end_bernoulli = load_metrics(\"lastfm_alternative_end2end_g_proposed_small_\"\n",
    "                                 \"d_proposed_r_proposed_bernoulli.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Training Strategies\n",
    "\n",
    "We compare the proposed training strategy with two alternative ones.\n",
    "\n",
    "- **proposed**: pretrain G and D in the first stage, and then train R and D (while G is fixed) in the second stage.\n",
    "- **joint**: pretrain G and D in the first stage, and then train G and R (like viewing R as part of G) jointly with D in the second stage.\n",
    "- **end-to-end**: train G, R and D jointly in one stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Two-stage Training Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(x, m, smooth, k=None, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        to_plot = np.nanmean(x['score_matrix_means'][:, m], 1)\n",
    "        if smooth == None or smooth == 'none':\n",
    "            plt.plot(x['steps'], to_plot, '-', zorder=1, **kwargs)\n",
    "        elif smooth == 'avg':\n",
    "            smoothed = movingaverage(to_plot, k)\n",
    "            plt.plot(x['steps'][h:-h], smoothed, '-', zorder=1, **kwargs)\n",
    "        elif smooth == 'med':\n",
    "            smoothed = scipy.signal.medfilt(to_plot, k)[h:-h]\n",
    "            plt.plot(x['steps'][h:-h], smoothed, '-', zorder=1, **kwargs)\n",
    "        if smooth is not None and smooth != 'none':\n",
    "            plt.plot(x['steps'], to_plot, '-', linewidth=.3, color='0.7',\n",
    "                     zorder=0)\n",
    "\n",
    "def plot_tonal_distance(x, m, smooth, k=None, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        to_plot = x['score_pair_matrix_means'][:, 0]\n",
    "        if smooth == None or smooth == 'none':\n",
    "            plt.plot(x['steps'], to_plot, '-', zorder=1, **kwargs)\n",
    "        elif smooth == 'avg':\n",
    "            smoothed = movingaverage(to_plot, k)\n",
    "            plt.plot(x['steps'][h:-h], smoothed, '-', zorder=1, **kwargs)\n",
    "        elif smooth == 'med':\n",
    "            smoothed = scipy.signal.medfilt(to_plot, k)[h:-h]\n",
    "            plt.plot(x['steps'][h:-h], smoothed, '-', zorder=1, **kwargs)\n",
    "        if smooth is not None and smooth != 'none':\n",
    "            plt.plot(x['steps'], to_plot, '-', linewidth=.3, color='0.7',\n",
    "                     zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "h = (k - 1)//2\n",
    "smooth = 'med' # 'avg', med', None\n",
    "\n",
    "locs = [3, 2, 3, 2, 4, 3, 2]\n",
    "ylims = [(0, 1), (0, 20), (0, 1), (0, 1), (0, 1), (0, 1), (0, 10)]\n",
    "\n",
    "def plot_metrics(m, save=False, close=False):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    plt.gca().set_prop_cycle('color', colors[:3] + colors[4:])\n",
    "\n",
    "    plot_metric(pretrained_proposed, m, smooth, k, label='pretrain',\n",
    "                linewidth=.8)\n",
    "    plot_metric(proposed_round, m, smooth, k, label='proposed (+DBNs)',\n",
    "                linewidth=.8)\n",
    "    plot_metric(proposed_bernoulli, m, smooth, k, label='proposed (+SBNs)',\n",
    "                linewidth=.8)\n",
    "    plot_metric(joint_round, m, smooth, k, label='joint (+DBNs)', linewidth=.8)\n",
    "    plot_metric(joint_bernoulli, m, smooth, k, label='joint (+SBNs)',\n",
    "                linewidth=.8)\n",
    "\n",
    "    plt.axhline(y=np.nanmean(train[()]['score_matrix_mean'][m, :]),\n",
    "                color='r', linestyle='--', linewidth=1.0, zorder=0)\n",
    "    plt.xlabel('step', fontweight='bold')\n",
    "    plt.ylabel(metric_names[m], fontweight='bold')\n",
    "    plt.gca().set_xlim(left=0)\n",
    "    plt.ylim(ylims[m][0], ylims[m][1])\n",
    "    plt.legend(loc=locs[m], prop={'size': 12, 'weight': 'bold'})\n",
    "    plt.setp(plt.gca().spines.values(), linewidth=1.5)\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    plt.tick_params(direction='in')\n",
    "    if save:\n",
    "        filepath = os.path.join(result_dir, 'two-stage',\n",
    "                                'two-stage_{}.{}'.format(metric_file_names[m],\n",
    "                                                         extension))\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "    if close:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in range(7):\n",
    "    plt.figure()\n",
    "    plot_metrics(m, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "h = (k - 1)//2\n",
    "smooth = 'med' # 'avg', 'med', None\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.gca().set_prop_cycle('color', colors[:3] + colors[4:])\n",
    "\n",
    "plot_tonal_distance(pretrained_proposed, m, smooth, k, label='pretrain',\n",
    "                    linewidth=.8)\n",
    "plot_tonal_distance(proposed_bernoulli, m, smooth, k, label='DBNs (proposed)',\n",
    "                    linewidth=.8)\n",
    "plot_tonal_distance(proposed_round, m, smooth, k, label='SBNs (proposed)',\n",
    "                    linewidth=.8)\n",
    "plot_tonal_distance(joint_round, m, smooth, k, label='DBNs (joint)',\n",
    "                    linewidth=.8)\n",
    "plot_tonal_distance(joint_bernoulli, m, smooth, k, label='SBNs (joint)',\n",
    "                    linewidth=.8)\n",
    "\n",
    "plt.axhline(y=train[()]['score_pair_matrix_mean'][0], color='tab:red',\n",
    "            linestyle='--', linewidth=1.0, zorder=0)\n",
    "plt.xlabel('step', fontweight='bold')\n",
    "plt.ylabel('tonal distance', fontweight='bold')\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=3, prop={'size': 12, 'weight': 'bold'})\n",
    "plt.setp(plt.gca().spines.values(), linewidth=1.5)\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "plt.tick_params(direction='in')\n",
    "\n",
    "filepath = os.path.join(result_dir, 'two-stage',\n",
    "                        'two-stage_tonal_distance.' + extension)\n",
    "plt.savefig(filepath, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of End-to-end Training Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "h = (k - 1)//2\n",
    "smooth = 'med' # 'avg', med', None\n",
    "\n",
    "locs_end2end = [1, 1, 1, 1, 4, 4, 1]\n",
    "ylims_end2end = [(0, 1), (0, 20), (0, 1), (0, 1), (0, 1), (0, 1), (0, 8)]\n",
    "\n",
    "def plot_metrics(m, save=False, close=False):\n",
    "    plot_metric(end2end_round, m, smooth, k, label='end-to-end (+DBNs)',\n",
    "                linewidth=.8)\n",
    "    plot_metric(end2end_bernoulli, m, smooth, k, label='end-to-end (+SBNs)',\n",
    "                linewidth=.8)\n",
    "\n",
    "    plt.axhline(y=np.nanmean(train[()]['score_matrix_mean'][m, :]),\n",
    "                color='tab:red', linestyle='--', linewidth=1.0, zorder=0)\n",
    "    plt.xlabel('step', fontweight='bold')\n",
    "    plt.ylabel(metric_names[m], fontweight='bold')\n",
    "    plt.gca().set_xlim(left=0)\n",
    "    plt.ylim(ylims_end2end[m][0], ylims_end2end[m][1])\n",
    "    plt.legend(loc=locs_end2end[m], prop={'size': 12, 'weight': 'bold'})\n",
    "    plt.setp(plt.gca().spines.values(), linewidth=1.5)\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    plt.tick_params(direction='in')\n",
    "\n",
    "    if save:\n",
    "        filepath = os.path.join(result_dir, 'end2end',\n",
    "                                'end2end_{}.{}'.format(metric_file_names[m],\n",
    "                                                       extension))\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "    if close:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in range(7):\n",
    "    plt.figure()\n",
    "    plot_metrics(m, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of the Shared/private and Multi-stream Design of the Discriminator\n",
    "\n",
    "We compare the proposed model with its ablated version and a baseline model.\n",
    "\n",
    "- **ablated**: remove the onset/offset and chroma streams.\n",
    "- **baseline**: use only a shared discriminator without the shared/private design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "h = (k - 1)//2\n",
    "m = 2\n",
    "smooth = 'med' # 'avg', med', None\n",
    "\n",
    "locs_ablated = [1, 1, 1, 1, 4, 4, 1]\n",
    "ylims_ablated = [(0, 1), (0, 11), (0, 1), (0, 1), (0, 1), (.5, 1), (0, 8)]\n",
    "\n",
    "def plot_metrics(m, save=False, close=False):\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    plt.gca().set_prop_cycle('color', colors[:3] + colors[4:])\n",
    "\n",
    "    plot_metric(pretrained_proposed, m, smooth, k, label='proposed',\n",
    "                linewidth=.8)\n",
    "    plot_metric(pretrained_ablated, m, smooth, k,  label='ablated',\n",
    "                linewidth=.8)\n",
    "    plot_metric(pretrained_baseline, m, smooth, k,  label='baseline',\n",
    "                linewidth=.8)\n",
    "\n",
    "    plt.axhline(y=np.nanmean(train[()]['score_matrix_mean'][m, :]),\n",
    "                color='tab:red', linestyle='--', linewidth=1.0, zorder=0)\n",
    "    plt.xlabel('step', fontweight='bold')\n",
    "    plt.ylabel(metric_names[m], fontweight='bold')\n",
    "    plt.ylim(ylims_ablated[m][0], ylims_ablated[m][1])\n",
    "    plt.legend(loc=locs_ablated[m], prop={'size': 12, 'weight': 'bold'})\n",
    "    plt.setp(plt.gca().spines.values(), linewidth=1.5)\n",
    "    plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    plt.tick_params(direction='in')\n",
    "\n",
    "    if save:\n",
    "        filepath = os.path.join(result_dir, 'ablated',\n",
    "                                'ablated_{}.{}'.format(metric_file_names[m],\n",
    "                                                       extension))\n",
    "        plt.savefig(filepath, bbox_inches='tight')\n",
    "    if close:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for m in range(7):\n",
    "    plt.figure()\n",
    "    plot_metrics(m, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "h = (k-1)//2\n",
    "m = 0\n",
    "smooth = 'med' # 'med', None\n",
    "\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "plt.gca().set_prop_cycle('color', colors[:3] + colors[4:])\n",
    "\n",
    "plot_tonal_distance(pretrained_proposed, m, smooth, k, label='proposed',\n",
    "                    linewidth=.8)\n",
    "plot_tonal_distance(pretrained_ablated, m, smooth, k, label='ablated',\n",
    "                    linewidth=.8)\n",
    "plot_tonal_distance(pretrained_baseline, m, smooth, k, label='baseline',\n",
    "                    linewidth=.8)\n",
    "\n",
    "plt.axhline(y=train[()]['score_pair_matrix_mean'][0], color='tab:red',\n",
    "            linestyle='--', linewidth=1.0, zorder=0)\n",
    "plt.xlabel('step', fontweight='bold')\n",
    "plt.ylabel('tonal distance', fontweight='bold')\n",
    "plt.ylim(0.0, 2.5)\n",
    "plt.legend(loc=4, prop={'size': 12, 'weight': 'bold'})\n",
    "plt.setp(plt.gca().spines.values(), linewidth=1.5)\n",
    "plt.gca().yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "plt.tick_params(direction='in')\n",
    "\n",
    "filepath = os.path.join(result_dir, 'ablated',\n",
    "                        'ablated_tonal_distance.' + extension)\n",
    "plt.savefig(filepath, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
